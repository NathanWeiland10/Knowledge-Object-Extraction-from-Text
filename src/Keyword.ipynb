{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29455cc4-c5ed-4744-9836-c6b2a2816f2e",
   "metadata": {},
   "source": [
    "def analyze(text):   \n",
    "    experience_year=[]\n",
    "    experience_skills=[]\n",
    "    diploma=[]\n",
    "    diploma_major=[]   \n",
    "    for doc in nlp.pipe(text, disable=[\"tagger\"]):\n",
    "        skills = [e.text for e in doc.ents if e.label_ == 'SKILLS']\n",
    "    for name, proc in nlp2.pipeline:\n",
    "        doc = proc(doc)\n",
    "    for value, rel_dict in doc._.rel.items():\n",
    "        for e in doc.ents:\n",
    "            for b in doc.ents:\n",
    "                if e.start == value[0] and b.start == value[1]:\n",
    "                    if rel_dict['EXPERIENCE_IN'] >= 0.9:\n",
    "                        experience_skills.append(b.text)\n",
    "                        experience_year.append(e.text)\n",
    "                    if rel_dict['DEGREE_IN'] >= 0.9:\n",
    "                        diploma_major.append(b.text)\n",
    "                        diploma.append(e.text)\n",
    "    return skills, experience_skills, experience_year, diploma, diploma_major\n",
    "def analyze_jobs(item):\n",
    "    with open('./path_to_job_descriptions', 'w', encoding='utf-8') as file:\n",
    "        file.write('[')\n",
    "        for i,row in enumerate(item['Description']):\n",
    "            try:\n",
    "                skill, experience_skills, experience_year, diploma, diploma_major=analyze([row])\n",
    "                data=json.dumps({'Job ID':item['JOBID'][i],'Title':item['Title'][i],'Location':item['Location'][i],'Link':item['Link'][i],'Category':item['Category'][i],'document':row, 'skills':skill, 'experience skills':experience_skills, 'experience years': experience_year, 'diploma':diploma, 'diploma_major':diploma_major}, ensure_ascii=False)\n",
    "                file.write(data)\n",
    "                file.write(',')\n",
    "            except:\n",
    "                continue\n",
    "        file.write(']')\n",
    "analyze_jobs(path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20590bf-d269-4cd3-8a69-92ab23dd5ed4",
   "metadata": {},
   "source": [
    "job_net = Network(height='1000px', width='100%', bgcolor='#222222', font_color='white')\n",
    "\n",
    "job_net.barnes_hut()\n",
    "sources = data_graph['Job ID']\n",
    "targets = data_graph['skills']\n",
    "values=data_graph['years skills']\n",
    "sources_resume = data_graph_resume['document']\n",
    "targets_resume = data_graph_resume['skills']\n",
    "\n",
    "edge_data = zip(sources, targets, values )\n",
    "resume_edge=zip(sources_resume, targets_resume)\n",
    "for j,e in enumerate(edge_data):\n",
    "    src = e[0]\n",
    "    dst = e[1]\n",
    "    w = e[2]\n",
    "\n",
    "\n",
    "    job_net.add_node(src, src, color='#dd4b39', title=src)\n",
    "    job_net.add_node(dst, dst, title=dst)\n",
    "\n",
    "\n",
    "    if str(w).isdigit():\n",
    "        if w is None:\n",
    "\n",
    "            job_net.add_edge(src, dst, value=w, color='#00ff1e', label=w)\n",
    "        if 1<w<=5:\n",
    "            job_net.add_edge(src, dst, value=w, color='#FFFF00', label=w)\n",
    "        if w>5:\n",
    "            job_net.add_edge(src, dst, value=w, color='#dd4b39', label=w)\n",
    "\n",
    "    else:\n",
    "        job_net.add_edge(src, dst, value=0.1, dashes=True)for j,e in enumerate(resume_edge):\n",
    "    src = 'resume'\n",
    "    dst = e[1]\n",
    "\n",
    "    job_net.add_node(src, src, color='#dd4b39', title=src)\n",
    "    job_net.add_node(dst, dst, title=dst)\n",
    "    job_net.add_edge(src, dst, color='#00ff1e')neighbor_map = job_net.get_adj_list()for node in job_net.nodes:\n",
    "    node['title'] += ' Neighbors:<br>' + '<br>'.join(neighbor_map[node['id']])\n",
    "    node['value'] = len(neighbor_map[node['id']])# add neighbor data to node hover data\n",
    "job_net.show_buttons(filter_=['physics'])\n",
    "job_net.show('job_knolwedge_graph.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d0763b7-e899-421f-aca1-0809abef73d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting keyphrase-vectorizers\n",
      "  Downloading keyphrase_vectorizers-0.0.11-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/tiffany/.local/lib/python3.10/site-packages (from keyphrase-vectorizers) (1.26.4)\n",
      "Collecting spacy>=3.0.1 (from keyphrase-vectorizers)\n",
      "  Downloading spacy-3.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
      "Collecting spacy-transformers>=1.1.6 (from keyphrase-vectorizers)\n",
      "  Downloading spacy_transformers-1.3.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nltk>=3.6.1 (from keyphrase-vectorizers)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: scikit-learn>=1.0 in /home/tiffany/.local/lib/python3.10/site-packages (from keyphrase-vectorizers) (1.4.1.post1)\n",
      "Requirement already satisfied: scipy>=1.7.3 in /home/tiffany/.local/lib/python3.10/site-packages (from keyphrase-vectorizers) (1.12.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/tiffany/.local/lib/python3.10/site-packages (from keyphrase-vectorizers) (5.9.8)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk>=3.6.1->keyphrase-vectorizers) (8.0.3)\n",
      "Requirement already satisfied: joblib in /home/tiffany/.local/lib/python3.10/site-packages (from nltk>=3.6.1->keyphrase-vectorizers) (1.3.2)\n",
      "Collecting regex>=2021.8.3 (from nltk>=3.6.1->keyphrase-vectorizers)\n",
      "  Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tqdm (from nltk>=3.6.1->keyphrase-vectorizers)\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /home/tiffany/.local/lib/python3.10/site-packages (from scikit-learn>=1.0->keyphrase-vectorizers) (3.3.0)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy>=3.0.1->keyphrase-vectorizers)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy>=3.0.1->keyphrase-vectorizers)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy>=3.0.1->keyphrase-vectorizers)\n",
      "  Downloading murmurhash-1.0.10-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy>=3.0.1->keyphrase-vectorizers)\n",
      "  Downloading cymem-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy>=3.0.1->keyphrase-vectorizers)\n",
      "  Downloading preshed-3.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.3.0,>=8.2.2 (from spacy>=3.0.1->keyphrase-vectorizers)\n",
      "  Downloading thinc-8.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy>=3.0.1->keyphrase-vectorizers)\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy>=3.0.1->keyphrase-vectorizers)\n",
      "  Downloading srsly-2.4.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy>=3.0.1->keyphrase-vectorizers)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.4.0,>=0.1.0 (from spacy>=3.0.1->keyphrase-vectorizers)\n",
      "  Downloading weasel-0.3.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting typer<0.10.0,>=0.3.0 (from spacy>=3.0.1->keyphrase-vectorizers)\n",
      "  Downloading typer-0.9.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<7.0.0,>=5.2.1 (from spacy>=3.0.1->keyphrase-vectorizers)\n",
      "  Downloading smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/tiffany/.local/lib/python3.10/site-packages (from spacy>=3.0.1->keyphrase-vectorizers) (2.31.0)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy>=3.0.1->keyphrase-vectorizers)\n",
      "  Downloading pydantic-2.6.3-py3-none-any.whl.metadata (84 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /home/tiffany/.local/lib/python3.10/site-packages (from spacy>=3.0.1->keyphrase-vectorizers) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (59.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/tiffany/.local/lib/python3.10/site-packages (from spacy>=3.0.1->keyphrase-vectorizers) (23.2)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy>=3.0.1->keyphrase-vectorizers)\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting transformers<4.37.0,>=3.4.0 (from spacy-transformers>=1.1.6->keyphrase-vectorizers)\n",
      "  Downloading transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.8/126.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.8.0 in /home/tiffany/.local/lib/python3.10/site-packages (from spacy-transformers>=1.1.6->keyphrase-vectorizers) (2.2.1)\n",
      "Collecting spacy-alignments<1.0.0,>=0.7.2 (from spacy-transformers>=1.1.6->keyphrase-vectorizers)\n",
      "  Downloading spacy_alignments-0.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.1->keyphrase-vectorizers)\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.16.3 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.1->keyphrase-vectorizers)\n",
      "  Downloading pydantic_core-2.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/tiffany/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.1->keyphrase-vectorizers) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/tiffany/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.1->keyphrase-vectorizers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.1->keyphrase-vectorizers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.1->keyphrase-vectorizers) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.1->keyphrase-vectorizers) (2020.6.20)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy>=3.0.1->keyphrase-vectorizers)\n",
      "  Downloading blis-0.7.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.2.2->spacy>=3.0.1->keyphrase-vectorizers)\n",
      "  Downloading confection-0.1.4-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /home/tiffany/.local/lib/python3.10/site-packages (from torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (3.13.1)\n",
      "Requirement already satisfied: sympy in /home/tiffany/.local/lib/python3.10/site-packages (from torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (1.12)\n",
      "Requirement already satisfied: networkx in /home/tiffany/.local/lib/python3.10/site-packages (from torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (3.2.1)\n",
      "Requirement already satisfied: fsspec in /home/tiffany/.local/lib/python3.10/site-packages (from torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/tiffany/.local/lib/python3.10/site-packages (from torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/tiffany/.local/lib/python3.10/site-packages (from torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/tiffany/.local/lib/python3.10/site-packages (from torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/tiffany/.local/lib/python3.10/site-packages (from torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/tiffany/.local/lib/python3.10/site-packages (from torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/tiffany/.local/lib/python3.10/site-packages (from torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/tiffany/.local/lib/python3.10/site-packages (from torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/tiffany/.local/lib/python3.10/site-packages (from torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/tiffany/.local/lib/python3.10/site-packages (from torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/tiffany/.local/lib/python3.10/site-packages (from torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/tiffany/.local/lib/python3.10/site-packages (from torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/tiffany/.local/lib/python3.10/site-packages (from torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/tiffany/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (12.2.140)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers<4.37.0,>=3.4.0->spacy-transformers>=1.1.6->keyphrase-vectorizers)\n",
      "  Downloading huggingface_hub-0.21.4-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers<4.37.0,>=3.4.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (5.4.1)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers<4.37.0,>=3.4.0->spacy-transformers>=1.1.6->keyphrase-vectorizers)\n",
      "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers<4.37.0,>=3.4.0->spacy-transformers>=1.1.6->keyphrase-vectorizers)\n",
      "  Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting cloudpathlib<0.17.0,>=0.7.0 (from weasel<0.4.0,>=0.1.0->spacy>=3.0.1->keyphrase-vectorizers)\n",
      "  Downloading cloudpathlib-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/tiffany/.local/lib/python3.10/site-packages (from jinja2->spacy>=3.0.1->keyphrase-vectorizers) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/tiffany/.local/lib/python3.10/site-packages (from sympy->torch>=1.8.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (1.3.0)\n",
      "Downloading keyphrase_vectorizers-0.0.11-py3-none-any.whl (29 kB)\n",
      "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0mm\n",
      "\u001b[?25hDownloading spacy-3.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading spacy_transformers-1.3.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (197 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.9/197.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (46 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.6/181.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading murmurhash-1.0.10-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
      "Downloading preshed-3.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (156 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.9/156.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.6.3-py3-none-any.whl (395 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.2/395.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.0/774.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading spacy_alignments-0.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (313 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.0/314.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.4.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (493 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.0/493.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading thinc-8.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (922 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m922.3/922.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.3.4-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading blis-0.7.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading confection-0.1.4-py3-none-any.whl (35 kB)\n",
      "Downloading huggingface_hub-0.21.4-py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.4/346.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: cymem, wasabi, typer, tqdm, spacy-loggers, spacy-legacy, spacy-alignments, smart-open, safetensors, regex, pydantic-core, murmurhash, langcodes, cloudpathlib, catalogue, blis, annotated-types, srsly, pydantic, preshed, nltk, huggingface-hub, tokenizers, confection, weasel, transformers, thinc, spacy, spacy-transformers, keyphrase-vectorizers\n",
      "Successfully installed annotated-types-0.6.0 blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.16.0 confection-0.1.4 cymem-2.0.8 huggingface-hub-0.21.4 keyphrase-vectorizers-0.0.11 langcodes-3.3.0 murmurhash-1.0.10 nltk-3.8.1 preshed-3.0.9 pydantic-2.6.3 pydantic-core-2.16.3 regex-2023.12.25 safetensors-0.4.2 smart-open-6.4.0 spacy-3.7.4 spacy-alignments-0.9.1 spacy-legacy-3.0.12 spacy-loggers-1.0.5 spacy-transformers-1.3.4 srsly-2.4.8 thinc-8.2.3 tokenizers-0.15.2 tqdm-4.66.2 transformers-4.36.2 typer-0.9.0 wasabi-1.1.2 weasel-0.3.4\n"
     ]
    }
   ],
   "source": [
    "!pip install keyphrase-vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "496c6d59-509e-4726-a93b-5e3fe3fa4b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'binary': False, 'custom_pos_tagger': None, 'dtype': <class 'numpy.int64'>, 'lowercase': True, 'max_df': None, 'min_df': None, 'pos_pattern': '<J.*>*<N.*>+', 'spacy_exclude': None, 'spacy_pipeline': 'en_core_web_sm', 'stop_words': 'english', 'workers': 1}\n"
     ]
    }
   ],
   "source": [
    "from keyphrase_vectorizers import KeyphraseCountVectorizer\n",
    "\n",
    "docs = [\"\"\"Supervised learning is the machine learning task of learning a function that\n",
    "         maps an input to an output based on example input-output pairs. It infers a\n",
    "         function from labeled training data consisting of a set of training examples.\n",
    "         In supervised learning, each example is a pair consisting of an input object\n",
    "         (typically a vector) and a desired output value (also called the supervisory signal). \n",
    "         A supervised learning algorithm analyzes the training data and produces an inferred function, \n",
    "         which can be used for mapping new examples. An optimal scenario will allow for the \n",
    "         algorithm to correctly determine the class labels for unseen instances. This requires \n",
    "         the learning algorithm to generalize from the training data to unseen situations in a \n",
    "         'reasonable' way (see inductive bias).\"\"\", \n",
    "             \n",
    "        \"\"\"Keywords are defined as phrases that capture the main topics discussed in a document. \n",
    "        As they offer a brief yet precise summary of document content, they can be utilized for various applications. \n",
    "        In an information retrieval environment, they serve as an indication of document relevance for users, as the list \n",
    "        of keywords can quickly help to determine whether a given document is relevant to their interest. \n",
    "        As keywords reflect a document's main topics, they can be utilized to classify documents into groups \n",
    "        by measuring the overlap between the keywords assigned to them. Keywords are also used proactively \n",
    "        in information retrieval.\"\"\"]\n",
    "        \n",
    "# Init default vectorizer.\n",
    "vectorizer = KeyphraseCountVectorizer()\n",
    "\n",
    "# Print parameters\n",
    "print(vectorizer.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95235d12-dcc8-41ad-bdcd-be0735ab0ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 13:07:31,867 - KeyphraseVectorizer - INFO - It looks like the selected spaCy pipeline is not downloaded yet. It is attempted to download the spaCy pipeline now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /home/tiffany/.local/lib/python3.10/site-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/tiffany/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/tiffany/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/tiffany/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/tiffany/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/tiffany/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /home/tiffany/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/tiffany/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/tiffany/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/tiffany/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/tiffany/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/tiffany/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/tiffany/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/tiffany/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/tiffany/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/tiffany/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.6.3)\n",
      "Requirement already satisfied: jinja2 in /home/tiffany/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (59.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/tiffany/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/tiffany/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/tiffany/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/tiffany/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /home/tiffany/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/tiffany/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/tiffany/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2020.6.20)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/tiffany/.local/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/tiffany/.local/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/lib/python3/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.0.3)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /home/tiffany/.local/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/tiffany/.local/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.4)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.7.1\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiffany/.local/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/tiffany/.local/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 3 1 0 3 2 1 1 1 1 0 0 3 1 1 1 0 1 1 0 0 1 1 3 1 0 3 3 1 1 0 0 1 0\n",
      "  0 0 1 1 0 0]\n",
      " [1 1 1 0 0 2 0 0 0 0 0 0 1 1 0 0 0 0 2 0 0 5 1 0 0 0 0 1 0 0 0 0 5 1 0 1\n",
      "  1 1 0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# After initializing the vectorizer, it can be fitted\n",
    "# to learn the keyphrases from the text documents.\n",
    "# Afterwards, the vectorizer can transform the documents \n",
    "# to a document-keyphrase matrix.\n",
    "# Matrix rows indicate the documents and columns indicate the unique keyphrases.\n",
    "# Each cell represents the count.\n",
    "\n",
    "document_keyphrase_matrix = vectorizer.fit_transform(docs).toarray()\n",
    "print(document_keyphrase_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a598d63d-a62c-4efe-bb8c-00f596dd56b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['document relevance' 'various applications' 'overlap' 'training data'\n",
      " 'unseen situations' 'information retrieval' 'input' 'example'\n",
      " 'input object' 'unseen instances' 'inductive bias' 'way'\n",
      " 'document content' 'information retrieval environment' 'output' 'set'\n",
      " 'machine' 'task' 'main topics' 'optimal scenario' 'new examples'\n",
      " 'keywords' 'indication' 'output pairs' 'supervised learning algorithm'\n",
      " 'function' 'class labels' 'precise summary' 'supervised learning'\n",
      " 'algorithm' 'vector' 'output value' 'document' 'groups'\n",
      " 'supervisory signal' 'list' 'documents' 'users' 'pair'\n",
      " 'training examples' 'interest' 'phrases']\n"
     ]
    }
   ],
   "source": [
    "# After learning the keyphrases, they can be returned.\n",
    "keyphrases = vectorizer.get_feature_names_out()\n",
    "print(keyphrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "705b93e5-f831-4682-8ace-5b79b2c8295a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting keybert\n",
      "  Downloading keybert-0.8.4.tar.gz (29 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.18.5 in /home/tiffany/.local/lib/python3.10/site-packages (from keybert) (1.26.4)\n",
      "Collecting rich>=10.4.0 (from keybert)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in /home/tiffany/.local/lib/python3.10/site-packages (from keybert) (1.4.1.post1)\n",
      "Collecting sentence-transformers>=0.3.8 (from keybert)\n",
      "  Downloading sentence_transformers-2.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.4.0->keybert)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/tiffany/.local/lib/python3.10/site-packages (from rich>=10.4.0->keybert) (2.17.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/tiffany/.local/lib/python3.10/site-packages (from scikit-learn>=0.22.2->keybert) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/tiffany/.local/lib/python3.10/site-packages (from scikit-learn>=0.22.2->keybert) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/tiffany/.local/lib/python3.10/site-packages (from scikit-learn>=0.22.2->keybert) (3.3.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /home/tiffany/.local/lib/python3.10/site-packages (from sentence-transformers>=0.3.8->keybert) (4.36.2)\n",
      "Requirement already satisfied: tqdm in /home/tiffany/.local/lib/python3.10/site-packages (from sentence-transformers>=0.3.8->keybert) (4.66.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/tiffany/.local/lib/python3.10/site-packages (from sentence-transformers>=0.3.8->keybert) (2.2.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /home/tiffany/.local/lib/python3.10/site-packages (from sentence-transformers>=0.3.8->keybert) (0.21.4)\n",
      "Requirement already satisfied: Pillow in /usr/lib/python3/dist-packages (from sentence-transformers>=0.3.8->keybert) (9.0.1)\n",
      "Requirement already satisfied: filelock in /home/tiffany/.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/tiffany/.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (2024.2.0)\n",
      "Requirement already satisfied: requests in /home/tiffany/.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/tiffany/.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (4.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/tiffany/.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (23.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.4.0->keybert)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: sympy in /home/tiffany/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.12)\n",
      "Requirement already satisfied: networkx in /home/tiffany/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/tiffany/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/tiffany/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/tiffany/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/tiffany/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/tiffany/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/tiffany/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/tiffany/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/tiffany/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/tiffany/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/tiffany/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/tiffany/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/tiffany/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/tiffany/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/tiffany/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.2.140)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/tiffany/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.3.8->keybert) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/tiffany/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.3.8->keybert) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/tiffany/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.3.8->keybert) (0.4.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/tiffany/.local/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (2.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/tiffany/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (2020.6.20)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/tiffany/.local/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.3.0)\n",
      "Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentence_transformers-2.5.1-py3-none-any.whl (156 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: keybert\n",
      "  Building wheel for keybert (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keybert: filename=keybert-0.8.4-py3-none-any.whl size=39230 sha256=67ca9b9dc959dc5b36790a5bec4829d70325834b4e53988dfe444e59693bd46d\n",
      "  Stored in directory: /home/tiffany/.cache/pip/wheels/97/ef/4c/6588bd7072b0cc04225b40e639b991e49ebd4e21fb81f0acee\n",
      "Successfully built keybert\n",
      "Installing collected packages: mdurl, markdown-it-py, rich, sentence-transformers, keybert\n",
      "Successfully installed keybert-0.8.4 markdown-it-py-3.0.0 mdurl-0.1.2 rich-13.7.1 sentence-transformers-2.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install keybert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0be7b4b-2b85-425f-85b4-3a416817c5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 13:08:16.405796: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-11 13:08:16.405915: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-11 13:08:16.428214: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-11 13:08:16.487429: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-11 13:08:17.417556: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/tiffany/.local/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72857cbaf1fa439d87ae6024634332d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dad421ab9c14889bdeb4b0beffd41b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03fc749d8fb04334a55d5f9fbefa2a99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3518da5b01a24f9d874134132f40291d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a5b578708d4f838aac34a499b04867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab6763d620224e30896d740f99d2663f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e01a90e589cb406d9b7ccbf0cff46cfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69521d8c14b411488ce5500c1962233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c894109aa44c4b9c6a9fa45b8ff98c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "618e23b80d6343cabb40162f3314e548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5411c4ba7f448a4a64e51d3f62b4484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keybert import KeyBERT\n",
    "\n",
    "docs = [\"\"\"Supervised learning is the machine learning task of learning a function that\n",
    "         maps an input to an output based on example input-output pairs. It infers a\n",
    "         function from labeled training data consisting of a set of training examples.\n",
    "         In supervised learning, each example is a pair consisting of an input object\n",
    "         (typically a vector) and a desired output value (also called the supervisory signal). \n",
    "         A supervised learning algorithm analyzes the training data and produces an inferred function, \n",
    "         which can be used for mapping new examples. An optimal scenario will allow for the \n",
    "         algorithm to correctly determine the class labels for unseen instances. This requires \n",
    "         the learning algorithm to generalize from the training data to unseen situations in a \n",
    "         'reasonable' way (see inductive bias).\"\"\", \n",
    "             \n",
    "        \"\"\"Keywords are defined as phrases that capture the main topics discussed in a document. \n",
    "        As they offer a brief yet precise summary of document content, they can be utilized for various applications. \n",
    "        In an information retrieval environment, they serve as an indication of document relevance for users, as the list \n",
    "        of keywords can quickly help to determine whether a given document is relevant to their interest. \n",
    "        As keywords reflect a document's main topics, they can be utilized to classify documents into groups \n",
    "        by measuring the overlap between the keywords assigned to them. Keywords are also used proactively \n",
    "        in information retrieval.\"\"\"]\n",
    "\n",
    "# Init KeyBERT\n",
    "kw_model = KeyBERT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4524c5e7-b2bb-4b37-9b25-fee0fb20c5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('supervised learning', 0.6779),\n",
       "  ('supervised', 0.6676),\n",
       "  ('signal supervised', 0.6152),\n",
       "  ('examples supervised', 0.6112),\n",
       "  ('labeled training', 0.6013)],\n",
       " [('keywords defined', 0.6997),\n",
       "  ('keywords quickly', 0.6376),\n",
       "  ('list keywords', 0.6375),\n",
       "  ('keywords used', 0.6373),\n",
       "  ('keywords assigned', 0.6354)]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kw_model.extract_keywords(docs=docs, keyphrase_ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddcf519-850f-4ee1-9d4c-9999a7f9d3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keyphrase_vectorizers import KeyphraseCountVectorizer\n",
    "\n",
    "kw_model.extract_keywords(docs=docs, vectorizer=KeyphraseCountVectorizer())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
